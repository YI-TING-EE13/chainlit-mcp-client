# LLM connection
OLLAMA_HOST=http://localhost:11434/v1
OLLAMA_KEY=ollama
OLLAMA_MODEL=nemotron-3-nano:latest

# UI display name
ASSISTANT_NAME=Nemotron

# Default chat generation settings
LLM_NUM_CTX=1048576
LLM_MAX_TOKENS=
LLM_TEMPERATURE=0.8
LLM_TOP_P=
LLM_TOP_K=
LLM_REPEAT_PENALTY=
LLM_NUM_PREDICT=

# MCP sampling defaults
SAMPLING_NUM_CTX=1048576
SAMPLING_MAX_TOKENS=4096
SAMPLING_TEMPERATURE=0.8
SAMPLING_TOP_P=
SAMPLING_TOP_K=
SAMPLING_REPEAT_PENALTY=
SAMPLING_NUM_PREDICT=

# Local token usage reporting
TOKEN_USAGE_ENABLED=true
TOKENIZER_MODEL=cl100k_base

# Long-term memory
MEMORY_ENABLED=true
MEMORY_DB_PATH=data/memory.db
MEMORY_DEFAULT_INCOGNITO=false
MEMORY_SUMMARY_ENABLED=true
MEMORY_SUMMARY_MAX_TOKENS=512
MEMORY_SUMMARY_SCHEDULER_ENABLED=true
MEMORY_SUMMARY_INTERVAL_SECONDS=600